import utils
import streamlit as st
from streaming import StreamHandler

from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain

st.set_page_config(page_title="åŸºæœ¬åŒ»è¯é—®ç­”", page_icon="ğŸ’¬")
st.header('ğŸ’¬åŸºæœ¬åŒ»è¯é—®ç­”')
st.write('ä¸ç”¨æˆ·è¿›è¡Œäº’åŠ¨å¯¹è¯ï¼Œæä¾›åŸºç¡€åŒ»å­¦ä¿¡æ¯æœåŠ¡ï¼Œå¦‚å¸¸è§ç—…ç—‡çš„è§£é‡Šå’ŒåŸºæœ¬æ²»ç–—å»ºè®®')

class Basic:

    def __init__(self):
        self.openai_model = utils.configure_openai()
    
    def setup_chain(self):
        llm = ChatOpenAI(model_name=self.openai_model, temperature=0.2, streaming=True)
        chain = ConversationChain(llm=llm, verbose=True)
        return chain
    
    @utils.enable_chat_history
    def main(self):
        chain = self.setup_chain()
        user_query = st.chat_input(placeholder="æ‚¨å¥½ï¼Œæˆ‘æ˜¯æœ¬è‰RAGåŒ»è¯æ™ºèƒ½åŠ©ç†ï¼Œå¸Œæœ›å¯ä»¥å¸®åˆ°æ‚¨ã€‚ç¥æ‚¨èº«ä½“æ£’æ£’ï¼")
        if user_query:
            utils.display_msg(user_query, 'user')
            with st.chat_message("assistant"):
                st_cb = StreamHandler(st.empty())
                result = chain.invoke(
                    {"input":user_query},
                    {"callbacks": [st_cb]}
                )
                response = result["response"]
                st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    obj = Basic()
    obj.main()
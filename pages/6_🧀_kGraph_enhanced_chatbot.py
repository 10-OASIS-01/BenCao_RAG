import utils
import streamlit as st
from streaming import StreamHandler
from langchain_community.graphs import Neo4jGraph
from langchain_openai import ChatOpenAI
from langchain.chains import GraphCypherQAChain
from langchain_core.prompts import ChatPromptTemplate
from langchain.memory import ConversationBufferMemory

st.set_page_config(page_title="çŸ¥è¯†å›¾è°±å¢å¼ºåŒ»è¯é—®ç­”", page_icon="ğŸ§€")
st.header('ğŸ§€çŸ¥è¯†å›¾è°±å¢å¼ºåŒ»è¯é—®ç­”')
st.write('åˆ©ç”¨åŒ»å­¦çŸ¥è¯†å›¾è°±æä¾›æ›´æ·±å±‚æ¬¡å’Œç»“æ„åŒ–çš„åŒ»å­¦ä¿¡æ¯å“åº”ï¼Œå¦‚è¯ç‰©ç›¸äº’ä½œç”¨ã€ç—…ç—‡ä¸æ²»ç–—æ–¹æ¡ˆçš„å…³è”ç­‰ã€‚')


class Basic:

    def __init__(self):
        self.openai_model = utils.configure_openai()

    # @st.cache_resource
    def setup_chain(self):
        st.empty()
        memory = ConversationBufferMemory()
        llm = ChatOpenAI(model_name=self.openai_model, temperature=0.2, streaming=True)
        chain = GraphCypherQAChain.from_llm(llm=llm, graph=enhanced_graph,
                                            verbose=False, validate_cypher=True,
                                            return_direct=True, memory=memory)
        return chain

    def qa_chain(self):
        prompt = ChatPromptTemplate.from_template("ä½ æ˜¯ä¸€ä¸ªAIåŒ»ç”Ÿï¼Œåªé€šè¿‡åˆ†æ{pre_result}çš„å†…å®¹æ¥ä¸ºå¯¹æ–¹è¯¢é—®çš„{query}é—®é¢˜æä¾›ä¸“ä¸šå»ºè®®ã€‚"
                                                  "ç›´æ¥å»ºè®®"
                                                  "ä½¿ç”¨{pre_result}ä¸­çš„è¯æˆ–è€…å¥å­")
        llm = ChatOpenAI(model_name=self.openai_model, temperature=0.2, streaming=True, max_tokens=1000)
        chain = prompt | llm
        return chain

    @utils.enable_chat_history
    def main(self):
        # from neo4j.exceptions import CypherSyntaxError
        chain = self.setup_chain()
        qa_chain = self.qa_chain()
        user_query = st.chat_input(placeholder="æ‚¨å¥½ï¼Œæˆ‘æ˜¯æœ¬è‰RAGåŒ»è¯æ™ºèƒ½åŠ©ç†ï¼Œå¸Œæœ›å¯ä»¥å¸®åˆ°æ‚¨ã€‚ç¥æ‚¨èº«ä½“æ£’æ£’ï¼")
        if user_query:
            utils.display_msg(user_query, 'user')
            with st.chat_message("assistant"):
                st_cb = StreamHandler(st.empty())
                try:
                    result = chain.invoke(
                        {"query": user_query},
                    )
                    print(f"{result}\n")
                except BaseException as e:
                    result = {"query": user_query, "result": []}
                result_qa = qa_chain.invoke({"pre_result": result['result'], "query": result['query']},
                                            {"callbacks": [st_cb]})
                response = result_qa.content
                st.session_state.messages.append({"role": "assistant", "content": response})


enhanced_graph = Neo4jGraph(url="bolt://localhost:7687", username="neo4j",
                            password="your_password", enhanced_schema=True)

if __name__ == "__main__":
    obj = Basic()
    obj.main()

